{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdda2f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imports\n",
    "from fugashi import Tagger\n",
    "import pandas as pd\n",
    "import torch\n",
    "from collections import Counter\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import unicodedata\n",
    "from datasets import load_dataset\n",
    "import itertools\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import transformers\n",
    "\n",
    "import torch\n",
    "from torch import cuda\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b082cad4",
   "metadata": {},
   "source": [
    "# The Data\n",
    "\n",
    "Converting test, train and val datasets which include kanji to be purely kana (furigana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a864398",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset universal_dependencies (C:/Users/brand/.cache/huggingface/datasets/universal_dependencies/ja_gsd/2.7.0/1ac001f0e8a0021f19388e810c94599f3ac13cc45d6b5b8c69f7847b2188bdf7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5734897c56eb4b34acb1e0bc176f68ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dev-s1</td>\n",
       "      <td>ただし、50周年ソングに変更後は、EDも歌つきのものが使われた。</td>\n",
       "      <td>[ただし, 、, 50, 周年, ソング, に, 変更, 後, は, 、, ED, も, 歌...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev-s2</td>\n",
       "      <td>私は初めてだったんだけど思っていたよりも魚は新鮮でした。</td>\n",
       "      <td>[私, は, 初めて, だっ, た, ん, だ, けど, 思っ, て, い, た, より, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dev-s4</td>\n",
       "      <td>セントラル・リーグ審判員の水落朋大は実兄。</td>\n",
       "      <td>[セントラル, ・, リーグ, 審判, 員, の, 水落, 朋大, は, 実兄, 。]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dev-s5</td>\n",
       "      <td>多彩なライブアクトとともに、祝日前の渋谷の夜を盛り上げてくれそうだ。</td>\n",
       "      <td>[多彩, な, ライブ, アクト, と, とも, に, 、, 祝日, 前, の, 渋谷, の...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dev-s6</td>\n",
       "      <td>今作品では大会でのパラメータUPが非常に大きく、ALL999への育成は回復アイテムを投与しつ...</td>\n",
       "      <td>[今, 作品, で, は, 大会, で, の, パラメータ, UP, が, 非常, に, 大...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>dev-s507</td>\n",
       "      <td>お風呂大きくはないけれどお湯はきれい。</td>\n",
       "      <td>[お, 風呂, 大きく, は, ない, けれど, お, 湯, は, きれい, 。]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>dev-s508</td>\n",
       "      <td>新生闇軍団頭領。</td>\n",
       "      <td>[新生, 闇, 軍団, 頭領, 。]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>dev-s509</td>\n",
       "      <td>当初の説明と実際の施設の状態が違うという点も,川島町の住民の証言とよく似ています。</td>\n",
       "      <td>[当初, の, 説明, と, 実際, の, 施設, の, 状態, が, 違う, と, いう,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>dev-s510</td>\n",
       "      <td>それでいてこの対応である。</td>\n",
       "      <td>[それ, で, い, て, この, 対応, で, ある, 。]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>dev-s511</td>\n",
       "      <td>児童生徒が犠牲になる事態も多く、同市にある京田幼児園では園舎が倒壊し園児3名が圧死、園児14...</td>\n",
       "      <td>[児童, 生徒, が, 犠牲, に, なる, 事態, も, 多く, 、, 同市, に, ある...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          idx                                               text  \\\n",
       "0      dev-s1                   ただし、50周年ソングに変更後は、EDも歌つきのものが使われた。   \n",
       "1      dev-s2                       私は初めてだったんだけど思っていたよりも魚は新鮮でした。   \n",
       "2      dev-s4                              セントラル・リーグ審判員の水落朋大は実兄。   \n",
       "3      dev-s5                 多彩なライブアクトとともに、祝日前の渋谷の夜を盛り上げてくれそうだ。   \n",
       "4      dev-s6  今作品では大会でのパラメータUPが非常に大きく、ALL999への育成は回復アイテムを投与しつ...   \n",
       "..        ...                                                ...   \n",
       "496  dev-s507                                お風呂大きくはないけれどお湯はきれい。   \n",
       "497  dev-s508                                           新生闇軍団頭領。   \n",
       "498  dev-s509          当初の説明と実際の施設の状態が違うという点も,川島町の住民の証言とよく似ています。   \n",
       "499  dev-s510                                      それでいてこの対応である。   \n",
       "500  dev-s511  児童生徒が犠牲になる事態も多く、同市にある京田幼児園では園舎が倒壊し園児3名が圧死、園児14...   \n",
       "\n",
       "                                                tokens  \n",
       "0    [ただし, 、, 50, 周年, ソング, に, 変更, 後, は, 、, ED, も, 歌...  \n",
       "1    [私, は, 初めて, だっ, た, ん, だ, けど, 思っ, て, い, た, より, ...  \n",
       "2          [セントラル, ・, リーグ, 審判, 員, の, 水落, 朋大, は, 実兄, 。]  \n",
       "3    [多彩, な, ライブ, アクト, と, とも, に, 、, 祝日, 前, の, 渋谷, の...  \n",
       "4    [今, 作品, で, は, 大会, で, の, パラメータ, UP, が, 非常, に, 大...  \n",
       "..                                                 ...  \n",
       "496          [お, 風呂, 大きく, は, ない, けれど, お, 湯, は, きれい, 。]  \n",
       "497                                 [新生, 闇, 軍団, 頭領, 。]  \n",
       "498  [当初, の, 説明, と, 実際, の, 施設, の, 状態, が, 違う, と, いう,...  \n",
       "499                    [それ, で, い, て, この, 対応, で, ある, 。]  \n",
       "500  [児童, 生徒, が, 犠牲, に, なる, 事態, も, 多く, 、, 同市, に, ある...  \n",
       "\n",
       "[501 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_files = {\"train\": \"train_split.csv\", \"test\": \"test_split.csv\", 'val': 'val_split.csv'}\n",
    "dataset = load_dataset('universal_dependencies', 'ja_gsd')\n",
    "train_split = dataset['train']\n",
    "test_split = dataset['test']\n",
    "val_split = dataset['validation']\n",
    "\n",
    "train_split_df = pd.DataFrame(data=train_split, columns=train_split.features)\n",
    "train_split_df = train_split_df.drop(['lemmas','upos','xpos','feats','head','deprel','deps','misc'], axis=1)\n",
    "train_split_df\n",
    "\n",
    "test_split_df = pd.DataFrame(data=test_split, columns=test_split.features)\n",
    "test_split_df = test_split_df.drop(['lemmas','upos','xpos','feats','head','deprel','deps','misc'], axis=1)\n",
    "test_split_df\n",
    "\n",
    "val_split_df = pd.DataFrame(data=val_split, columns=val_split.features)\n",
    "val_split_df = val_split_df.drop(['lemmas','upos','xpos','feats','head','deprel','deps','misc'], axis=1)\n",
    "val_split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ed1afdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7027\n",
      "543\n",
      "501\n"
     ]
    }
   ],
   "source": [
    "print(len(train_split))\n",
    "print(len(test_split))\n",
    "print(len(val_split))\n",
    "#train_split['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afd62a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load kanji data\n",
    "kanji_df = pd.read_json(\"kanji.json\")\n",
    "kanji_df = kanji_df.drop(['strokes', 'grade', 'freq', 'jlpt_old', 'jlpt_new', 'meanings', 'wk_radicals', 'wk_readings_kun', 'wk_readings_on', 'wk_meanings', 'wk_level'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cdc3535",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>kana</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train-s1</td>\n",
       "      <td>ホッケーにはデンジャラスプレーの反則があるので、膝より上にボールを浮かすことは基本的に反則に...</td>\n",
       "      <td>[ホッケー, に, は, デンジャラス, プレー, の, 反則, が, ある, の, で, ...</td>\n",
       "      <td>ホッケーにはデンジャラスプレーのはんそくがあるので、しつよりじょうにボールをふかすことはきほ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train-s2</td>\n",
       "      <td>また行きたい、そんな気持ちにさせてくれるお店です。</td>\n",
       "      <td>[また, 行き, たい, 、, そんな, 気持ち, に, さ, せ, て, くれる, お, ...</td>\n",
       "      <td>またこうきたい、そんなきじちにさせてくれるおてんです。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train-s3</td>\n",
       "      <td>手に持った特殊な刃物を使ったアクロバティックな体術や、揚羽と薄羽同様にクナイや忍具を使って攻...</td>\n",
       "      <td>[手, に, 持っ, た, 特殊, な, 刃物, を, 使っ, た, アクロバティック, な...</td>\n",
       "      <td>しゅにじったとくしゅなじんぶつをしったアクロバティックなたいじゅつや、よううとはくうどうよう...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train-s4</td>\n",
       "      <td>3年次にはトータルオフェンスで2,892ヤードを獲得し、これは大学記録となった。</td>\n",
       "      <td>[3, 年次, に, は, トータル, オフェンス, で, 2, ,, 892, ヤード, ...</td>\n",
       "      <td>3ねんじにはトータルオフェンスで2,892ヤードをかくとくし、これはだいがくきろくとなった。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train-s5</td>\n",
       "      <td>葬儀の最中ですよ!</td>\n",
       "      <td>[葬儀, の, 最中, です, よ, !]</td>\n",
       "      <td>そうぎのさいちゅうですよ!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7022</th>\n",
       "      <td>train-s7160</td>\n",
       "      <td>「さくらちゃん」と呼ばれている。</td>\n",
       "      <td>[「, さくら, ちゃん, 」, と, 呼ば, れ, て, いる, 。]</td>\n",
       "      <td>「さくらちゃん」とこばれている。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7023</th>\n",
       "      <td>train-s7161</td>\n",
       "      <td>シェルマルケ氏は新憲法などをめぐり、アハメド暫定大統領と対立していた。</td>\n",
       "      <td>[シェルマルケ, 氏, は, 新, 憲法, など, を, めぐり, 、, アハメド, 暫定,...</td>\n",
       "      <td>シェルマルケしはしんけんほうなどをめぐり、アハメドざんていだいとうりょうとたいりつしていた。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7024</th>\n",
       "      <td>train-s7162</td>\n",
       "      <td>自らがオウム真理教ではない別のカルト団体に12年間所属していた経験をもとに,こう語りました。</td>\n",
       "      <td>[自ら, が, オウム, 真理, 教, で, は, ない, 別, の, カルト, 団体, に...</td>\n",
       "      <td>じらがオウムしんりきょうではないべつのカルトだんたいに12ねんかんしょぞくしていたけいけんを...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7025</th>\n",
       "      <td>train-s7163</td>\n",
       "      <td>紅い髪と同じ色の瞳という容姿に加え、眉と鎖骨の下の部分に二つずつ紅い球体が埋まっているという...</td>\n",
       "      <td>[紅い, 髪, と, 同じ, 色, の, 瞳, と, いう, 容姿, に, 加え, 、, 眉...</td>\n",
       "      <td>こういはつとどうじしょくのどうというようしにかえ、びとさこつのかのぶぶんににつずつこういきゅ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7026</th>\n",
       "      <td>train-s7164</td>\n",
       "      <td>“人生,棒に振らないように”するためにはカルト団体からの速やかな離脱が必要だと感じるのは記者...</td>\n",
       "      <td>[“, 人生, ,, 棒, に, 振ら, ない, よう, に, ”, する, ため, に, ...</td>\n",
       "      <td>“じんせい,ぼうにしんらないように”するためにはカルトだんたいからのそくやかなりだつがひつよ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7027 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              idx                                               text  \\\n",
       "0        train-s1  ホッケーにはデンジャラスプレーの反則があるので、膝より上にボールを浮かすことは基本的に反則に...   \n",
       "1        train-s2                          また行きたい、そんな気持ちにさせてくれるお店です。   \n",
       "2        train-s3  手に持った特殊な刃物を使ったアクロバティックな体術や、揚羽と薄羽同様にクナイや忍具を使って攻...   \n",
       "3        train-s4           3年次にはトータルオフェンスで2,892ヤードを獲得し、これは大学記録となった。   \n",
       "4        train-s5                                          葬儀の最中ですよ!   \n",
       "...           ...                                                ...   \n",
       "7022  train-s7160                                   「さくらちゃん」と呼ばれている。   \n",
       "7023  train-s7161                シェルマルケ氏は新憲法などをめぐり、アハメド暫定大統領と対立していた。   \n",
       "7024  train-s7162     自らがオウム真理教ではない別のカルト団体に12年間所属していた経験をもとに,こう語りました。   \n",
       "7025  train-s7163  紅い髪と同じ色の瞳という容姿に加え、眉と鎖骨の下の部分に二つずつ紅い球体が埋まっているという...   \n",
       "7026  train-s7164  “人生,棒に振らないように”するためにはカルト団体からの速やかな離脱が必要だと感じるのは記者...   \n",
       "\n",
       "                                                 tokens  \\\n",
       "0     [ホッケー, に, は, デンジャラス, プレー, の, 反則, が, ある, の, で, ...   \n",
       "1     [また, 行き, たい, 、, そんな, 気持ち, に, さ, せ, て, くれる, お, ...   \n",
       "2     [手, に, 持っ, た, 特殊, な, 刃物, を, 使っ, た, アクロバティック, な...   \n",
       "3     [3, 年次, に, は, トータル, オフェンス, で, 2, ,, 892, ヤード, ...   \n",
       "4                                 [葬儀, の, 最中, です, よ, !]   \n",
       "...                                                 ...   \n",
       "7022               [「, さくら, ちゃん, 」, と, 呼ば, れ, て, いる, 。]   \n",
       "7023  [シェルマルケ, 氏, は, 新, 憲法, など, を, めぐり, 、, アハメド, 暫定,...   \n",
       "7024  [自ら, が, オウム, 真理, 教, で, は, ない, 別, の, カルト, 団体, に...   \n",
       "7025  [紅い, 髪, と, 同じ, 色, の, 瞳, と, いう, 容姿, に, 加え, 、, 眉...   \n",
       "7026  [“, 人生, ,, 棒, に, 振ら, ない, よう, に, ”, する, ため, に, ...   \n",
       "\n",
       "                                                   kana  \n",
       "0     ホッケーにはデンジャラスプレーのはんそくがあるので、しつよりじょうにボールをふかすことはきほ...  \n",
       "1                           またこうきたい、そんなきじちにさせてくれるおてんです。  \n",
       "2     しゅにじったとくしゅなじんぶつをしったアクロバティックなたいじゅつや、よううとはくうどうよう...  \n",
       "3        3ねんじにはトータルオフェンスで2,892ヤードをかくとくし、これはだいがくきろくとなった。  \n",
       "4                                         そうぎのさいちゅうですよ!  \n",
       "...                                                 ...  \n",
       "7022                                   「さくらちゃん」とこばれている。  \n",
       "7023     シェルマルケしはしんけんほうなどをめぐり、アハメドざんていだいとうりょうとたいりつしていた。  \n",
       "7024  じらがオウムしんりきょうではないべつのカルトだんたいに12ねんかんしょぞくしていたけいけんを...  \n",
       "7025  こういはつとどうじしょくのどうというようしにかえ、びとさこつのかのぶぶんににつずつこういきゅ...  \n",
       "7026  “じんせい,ぼうにしんらないように”するためにはカルトだんたいからのそくやかなりだつがひつよ...  \n",
       "\n",
       "[7027 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As part of data collection, we need a dataset that is ONLY kana. \n",
    "# We could not find a dataset that had both kanji AND kana only version,\n",
    "# so we took a dataset and converted the kanji to kana. \n",
    "# kanji to kana is less ambiguous with how on vs kun readings work, but there is still some abiguity.\n",
    "# we recognize that here, in the dataset.\n",
    "def unkanjify(df):\n",
    "    new_sent = []\n",
    "    for word in df['tokens']:\n",
    "        #iterating list of chararacters\n",
    "        for char in word:\n",
    "            if char in kanji_df.columns:#is kanji\n",
    "                if char in kanji_df.columns or char in kanji_df.columns:\n",
    "                    if kanji_df[char].loc['readings_on']:\n",
    "                        new_sent.append(kanji_df[char].loc['readings_on'][0])\n",
    "                    else:\n",
    "                        new_sent.append(char)\n",
    "                #kun reading\n",
    "                else:\n",
    "                    for c in kanji_df[char].loc['readings_kun'][0]:\n",
    "                        if c == '.':\n",
    "                            continue\n",
    "                        new_sent.append(c)\n",
    "            else:#is not kanji\n",
    "                new_sent.append(char)\n",
    "    joined_sent = ''.join(new_sent)\n",
    "    return joined_sent\n",
    "\n",
    "# Applying the function to all splits (train, test and val)\n",
    "train_split_df['kana'] = train_split_df.apply(lambda x: unkanjify(x), axis=1) \n",
    "test_split_df['kana'] = test_split_df.apply(lambda x: unkanjify(x), axis=1) \n",
    "val_split_df['kana'] = val_split_df.apply(lambda x: unkanjify(x), axis=1) \n",
    "train_split_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6017b0",
   "metadata": {},
   "source": [
    "# Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912753c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kana is Y\n",
    "#text is X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3702ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58361eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "330a1788",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, text, labels, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text = text\n",
    "        self.targets = labels\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.text[index]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self, NUM_OUT):\n",
    "        super(BERTClass, self).__init__()\n",
    "                   \n",
    "        self.l1 = AutoModel.from_pretrained(\"cl-tohoku/bert-base-japanese\")#BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.pre_classifier = torch.nn.Linear(768, 32)\n",
    "        self.classifier = torch.nn.Linear(32, NUM_OUT)\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "#         pooler = torch.nn.Tanh()(pooler)\n",
    "#         pooler = self.dropout(pooler)\n",
    "        \n",
    "        output = self.softmax(output)\n",
    "        return output\n",
    "    \n",
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.CrossEntropyLoss()(outputs, targets)\n",
    "\n",
    "def train(model, training_loader, optimizer):\n",
    "    model.train()\n",
    "    for data in tqdm(training_loader):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss\n",
    "    \n",
    "def validation(model, testing_loader):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(testing_loader):\n",
    "            targets = data['targets']\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            outputs = torch.sigmoid(outputs).cpu().detach()\n",
    "            fin_outputs.extend(outputs)\n",
    "            fin_targets.extend(targets)\n",
    "    return torch.stack(fin_outputs), torch.stack(fin_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a802aa7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m NUM_OUT \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m \u001b[38;5;66;03m# binary task\u001b[39;00m\n\u001b[0;32m      6\u001b[0m LEARNING_RATE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2e-05\u001b[39m\n\u001b[1;32m----> 8\u001b[0m training_data \u001b[38;5;241m=\u001b[39m MultiLabelDataset(\u001b[43mtrain_X\u001b[49m, train_y, tokenizer, MAX_LEN)\n\u001b[0;32m      9\u001b[0m test_data \u001b[38;5;241m=\u001b[39m MultiLabelDataset(test_X, test_y, tokenizer, MAX_LEN)\n\u001b[0;32m     11\u001b[0m train_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: BATCH_SIZE,\n\u001b[0;32m     12\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshuffle\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     13\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_workers\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     14\u001b[0m                 }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_X' is not defined"
     ]
    }
   ],
   "source": [
    "#Vars\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 3\n",
    "NUM_OUT = 7 # binary task\n",
    "LEARNING_RATE = 2e-05\n",
    "\n",
    "training_data = MultiLabelDataset(train_X, train_y, tokenizer, MAX_LEN)\n",
    "test_data = MultiLabelDataset(test_X, test_y, tokenizer, MAX_LEN)\n",
    "\n",
    "train_params = {'batch_size': BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }    \n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(training_data, **train_params)\n",
    "testing_loader = torch.utils.data.DataLoader(test_data, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471d8dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTClass(NUM_OUT)\n",
    "model.to(device)    \n",
    "\n",
    "optimizer_bert = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c12e646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce2d735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a8fe08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
