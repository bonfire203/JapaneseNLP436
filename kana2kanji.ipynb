{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdda2f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import torch\n",
    "from collections import Counter\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import unicodedata\n",
    "from datasets import load_dataset\n",
    "import itertools\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import transformers\n",
    "from transformers import BertTokenizer, TFBertForMaskedLM\n",
    "\n",
    "import torch\n",
    "from torch import cuda\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1f504f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall TensorFLow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b082cad4",
   "metadata": {},
   "source": [
    "# The Data\n",
    "\n",
    "Converting test, train and val datasets which include kanji to be purely kana (furigana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a864398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset universal_dependencies/ja_gsd to C:/Users/brand/.cache/huggingface/datasets/universal_dependencies/ja_gsd/2.7.0/1ac001f0e8a0021f19388e810c94599f3ac13cc45d6b5b8c69f7847b2188bdf7...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8ef403e5684961b53042fa777c6b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8fbfd749f34bb59ec6860b0669587b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.66M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3a5e8489004cf2ac2b5c4e28a82cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/193k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb897e050934739a50b431e95676b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/205k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a25febefdbe430090216d5df280652e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/7027 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/501 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/543 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset universal_dependencies downloaded and prepared to C:/Users/brand/.cache/huggingface/datasets/universal_dependencies/ja_gsd/2.7.0/1ac001f0e8a0021f19388e810c94599f3ac13cc45d6b5b8c69f7847b2188bdf7. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a1190923964cfaa7369f07bd1deabf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dev-s1</td>\n",
       "      <td>ただし、50周年ソングに変更後は、EDも歌つきのものが使われた。</td>\n",
       "      <td>[ただし, 、, 50, 周年, ソング, に, 変更, 後, は, 、, ED, も, 歌...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev-s2</td>\n",
       "      <td>私は初めてだったんだけど思っていたよりも魚は新鮮でした。</td>\n",
       "      <td>[私, は, 初めて, だっ, た, ん, だ, けど, 思っ, て, い, た, より, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dev-s4</td>\n",
       "      <td>セントラル・リーグ審判員の水落朋大は実兄。</td>\n",
       "      <td>[セントラル, ・, リーグ, 審判, 員, の, 水落, 朋大, は, 実兄, 。]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dev-s5</td>\n",
       "      <td>多彩なライブアクトとともに、祝日前の渋谷の夜を盛り上げてくれそうだ。</td>\n",
       "      <td>[多彩, な, ライブ, アクト, と, とも, に, 、, 祝日, 前, の, 渋谷, の...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dev-s6</td>\n",
       "      <td>今作品では大会でのパラメータUPが非常に大きく、ALL999への育成は回復アイテムを投与しつ...</td>\n",
       "      <td>[今, 作品, で, は, 大会, で, の, パラメータ, UP, が, 非常, に, 大...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>dev-s507</td>\n",
       "      <td>お風呂大きくはないけれどお湯はきれい。</td>\n",
       "      <td>[お, 風呂, 大きく, は, ない, けれど, お, 湯, は, きれい, 。]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>dev-s508</td>\n",
       "      <td>新生闇軍団頭領。</td>\n",
       "      <td>[新生, 闇, 軍団, 頭領, 。]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>dev-s509</td>\n",
       "      <td>当初の説明と実際の施設の状態が違うという点も,川島町の住民の証言とよく似ています。</td>\n",
       "      <td>[当初, の, 説明, と, 実際, の, 施設, の, 状態, が, 違う, と, いう,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>dev-s510</td>\n",
       "      <td>それでいてこの対応である。</td>\n",
       "      <td>[それ, で, い, て, この, 対応, で, ある, 。]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>dev-s511</td>\n",
       "      <td>児童生徒が犠牲になる事態も多く、同市にある京田幼児園では園舎が倒壊し園児3名が圧死、園児14...</td>\n",
       "      <td>[児童, 生徒, が, 犠牲, に, なる, 事態, も, 多く, 、, 同市, に, ある...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          idx                                               text  \\\n",
       "0      dev-s1                   ただし、50周年ソングに変更後は、EDも歌つきのものが使われた。   \n",
       "1      dev-s2                       私は初めてだったんだけど思っていたよりも魚は新鮮でした。   \n",
       "2      dev-s4                              セントラル・リーグ審判員の水落朋大は実兄。   \n",
       "3      dev-s5                 多彩なライブアクトとともに、祝日前の渋谷の夜を盛り上げてくれそうだ。   \n",
       "4      dev-s6  今作品では大会でのパラメータUPが非常に大きく、ALL999への育成は回復アイテムを投与しつ...   \n",
       "..        ...                                                ...   \n",
       "496  dev-s507                                お風呂大きくはないけれどお湯はきれい。   \n",
       "497  dev-s508                                           新生闇軍団頭領。   \n",
       "498  dev-s509          当初の説明と実際の施設の状態が違うという点も,川島町の住民の証言とよく似ています。   \n",
       "499  dev-s510                                      それでいてこの対応である。   \n",
       "500  dev-s511  児童生徒が犠牲になる事態も多く、同市にある京田幼児園では園舎が倒壊し園児3名が圧死、園児14...   \n",
       "\n",
       "                                                tokens  \n",
       "0    [ただし, 、, 50, 周年, ソング, に, 変更, 後, は, 、, ED, も, 歌...  \n",
       "1    [私, は, 初めて, だっ, た, ん, だ, けど, 思っ, て, い, た, より, ...  \n",
       "2          [セントラル, ・, リーグ, 審判, 員, の, 水落, 朋大, は, 実兄, 。]  \n",
       "3    [多彩, な, ライブ, アクト, と, とも, に, 、, 祝日, 前, の, 渋谷, の...  \n",
       "4    [今, 作品, で, は, 大会, で, の, パラメータ, UP, が, 非常, に, 大...  \n",
       "..                                                 ...  \n",
       "496          [お, 風呂, 大きく, は, ない, けれど, お, 湯, は, きれい, 。]  \n",
       "497                                 [新生, 闇, 軍団, 頭領, 。]  \n",
       "498  [当初, の, 説明, と, 実際, の, 施設, の, 状態, が, 違う, と, いう,...  \n",
       "499                    [それ, で, い, て, この, 対応, で, ある, 。]  \n",
       "500  [児童, 生徒, が, 犠牲, に, なる, 事態, も, 多く, 、, 同市, に, ある...  \n",
       "\n",
       "[501 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_files = {\"train\": \"train_split.csv\", \"test\": \"test_split.csv\", 'val': 'val_split.csv'}\n",
    "dataset = load_dataset('universal_dependencies', 'ja_gsd')\n",
    "train_split = dataset['train']\n",
    "test_split = dataset['test']\n",
    "val_split = dataset['validation']\n",
    "\n",
    "train_split_df = pd.DataFrame(data=train_split, columns=train_split.features)\n",
    "train_split_df = train_split_df.drop(['lemmas','upos','xpos','feats','head','deprel','deps','misc'], axis=1)\n",
    "train_split_df\n",
    "\n",
    "test_split_df = pd.DataFrame(data=test_split, columns=test_split.features)\n",
    "test_split_df = test_split_df.drop(['lemmas','upos','xpos','feats','head','deprel','deps','misc'], axis=1)\n",
    "test_split_df\n",
    "\n",
    "val_split_df = pd.DataFrame(data=val_split, columns=val_split.features)\n",
    "val_split_df = val_split_df.drop(['lemmas','upos','xpos','feats','head','deprel','deps','misc'], axis=1)\n",
    "val_split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93de3ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>kana</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dev-s1</td>\n",
       "      <td>ただし、50周年ソングに変更後は、EDも歌つきのものが使われた。</td>\n",
       "      <td>[ただし, 、, 50, 周年, ソング, に, 変更, 後, は, 、, ED, も, 歌...</td>\n",
       "      <td>ただし、50しゅうねんソングにへんこうごは、EDもかつきのものがしわれた。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev-s2</td>\n",
       "      <td>私は初めてだったんだけど思っていたよりも魚は新鮮でした。</td>\n",
       "      <td>[私, は, 初めて, だっ, た, ん, だ, けど, 思っ, て, い, た, より, ...</td>\n",
       "      <td>しはしょめてだったんだけどしっていたよりもぎょはしんせんでした。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dev-s4</td>\n",
       "      <td>セントラル・リーグ審判員の水落朋大は実兄。</td>\n",
       "      <td>[セントラル, ・, リーグ, 審判, 員, の, 水落, 朋大, は, 実兄, 。]</td>\n",
       "      <td>セントラル・リーグしんはんいんのすいらくほうだいはじつけい。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dev-s5</td>\n",
       "      <td>多彩なライブアクトとともに、祝日前の渋谷の夜を盛り上げてくれそうだ。</td>\n",
       "      <td>[多彩, な, ライブ, アクト, と, とも, に, 、, 祝日, 前, の, 渋谷, の...</td>\n",
       "      <td>たさいなライブアクトとともに、しゅくにちぜんのじゅうこくのやをせいりじょうげてくれそうだ。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dev-s6</td>\n",
       "      <td>今作品では大会でのパラメータUPが非常に大きく、ALL999への育成は回復アイテムを投与しつ...</td>\n",
       "      <td>[今, 作品, で, は, 大会, で, の, パラメータ, UP, が, 非常, に, 大...</td>\n",
       "      <td>こんさくひんではだいかいでのパラメータUPがひじょうにだいきく、ALL999へのいくせいはか...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>dev-s507</td>\n",
       "      <td>お風呂大きくはないけれどお湯はきれい。</td>\n",
       "      <td>[お, 風呂, 大きく, は, ない, けれど, お, 湯, は, きれい, 。]</td>\n",
       "      <td>おふうろだいきくはないけれどおとうはきれい。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>dev-s508</td>\n",
       "      <td>新生闇軍団頭領。</td>\n",
       "      <td>[新生, 闇, 軍団, 頭領, 。]</td>\n",
       "      <td>しんせいあんぐんだんとうりょう。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>dev-s509</td>\n",
       "      <td>当初の説明と実際の施設の状態が違うという点も,川島町の住民の証言とよく似ています。</td>\n",
       "      <td>[当初, の, 説明, と, 実際, の, 施設, の, 状態, が, 違う, と, いう,...</td>\n",
       "      <td>とうしょのせつめいとじつさいのしせつのじょうたいがいうというてんも,せんとうちょうのじゅうみ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>dev-s510</td>\n",
       "      <td>それでいてこの対応である。</td>\n",
       "      <td>[それ, で, い, て, この, 対応, で, ある, 。]</td>\n",
       "      <td>それでいてこのたいおうである。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>dev-s511</td>\n",
       "      <td>児童生徒が犠牲になる事態も多く、同市にある京田幼児園では園舎が倒壊し園児3名が圧死、園児14...</td>\n",
       "      <td>[児童, 生徒, が, 犠牲, に, なる, 事態, も, 多く, 、, 同市, に, ある...</td>\n",
       "      <td>じどうせいとがぎせいになるじたいもたく、どうしにあるきょうでんようじえんではえんしゃがとうか...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          idx                                               text  \\\n",
       "0      dev-s1                   ただし、50周年ソングに変更後は、EDも歌つきのものが使われた。   \n",
       "1      dev-s2                       私は初めてだったんだけど思っていたよりも魚は新鮮でした。   \n",
       "2      dev-s4                              セントラル・リーグ審判員の水落朋大は実兄。   \n",
       "3      dev-s5                 多彩なライブアクトとともに、祝日前の渋谷の夜を盛り上げてくれそうだ。   \n",
       "4      dev-s6  今作品では大会でのパラメータUPが非常に大きく、ALL999への育成は回復アイテムを投与しつ...   \n",
       "..        ...                                                ...   \n",
       "496  dev-s507                                お風呂大きくはないけれどお湯はきれい。   \n",
       "497  dev-s508                                           新生闇軍団頭領。   \n",
       "498  dev-s509          当初の説明と実際の施設の状態が違うという点も,川島町の住民の証言とよく似ています。   \n",
       "499  dev-s510                                      それでいてこの対応である。   \n",
       "500  dev-s511  児童生徒が犠牲になる事態も多く、同市にある京田幼児園では園舎が倒壊し園児3名が圧死、園児14...   \n",
       "\n",
       "                                                tokens  \\\n",
       "0    [ただし, 、, 50, 周年, ソング, に, 変更, 後, は, 、, ED, も, 歌...   \n",
       "1    [私, は, 初めて, だっ, た, ん, だ, けど, 思っ, て, い, た, より, ...   \n",
       "2          [セントラル, ・, リーグ, 審判, 員, の, 水落, 朋大, は, 実兄, 。]   \n",
       "3    [多彩, な, ライブ, アクト, と, とも, に, 、, 祝日, 前, の, 渋谷, の...   \n",
       "4    [今, 作品, で, は, 大会, で, の, パラメータ, UP, が, 非常, に, 大...   \n",
       "..                                                 ...   \n",
       "496          [お, 風呂, 大きく, は, ない, けれど, お, 湯, は, きれい, 。]   \n",
       "497                                 [新生, 闇, 軍団, 頭領, 。]   \n",
       "498  [当初, の, 説明, と, 実際, の, 施設, の, 状態, が, 違う, と, いう,...   \n",
       "499                    [それ, で, い, て, この, 対応, で, ある, 。]   \n",
       "500  [児童, 生徒, が, 犠牲, に, なる, 事態, も, 多く, 、, 同市, に, ある...   \n",
       "\n",
       "                                                  kana  \n",
       "0                ただし、50しゅうねんソングにへんこうごは、EDもかつきのものがしわれた。  \n",
       "1                     しはしょめてだったんだけどしっていたよりもぎょはしんせんでした。  \n",
       "2                       セントラル・リーグしんはんいんのすいらくほうだいはじつけい。  \n",
       "3        たさいなライブアクトとともに、しゅくにちぜんのじゅうこくのやをせいりじょうげてくれそうだ。  \n",
       "4    こんさくひんではだいかいでのパラメータUPがひじょうにだいきく、ALL999へのいくせいはか...  \n",
       "..                                                 ...  \n",
       "496                             おふうろだいきくはないけれどおとうはきれい。  \n",
       "497                                   しんせいあんぐんだんとうりょう。  \n",
       "498  とうしょのせつめいとじつさいのしせつのじょうたいがいうというてんも,せんとうちょうのじゅうみ...  \n",
       "499                                    それでいてこのたいおうである。  \n",
       "500  じどうせいとがぎせいになるじたいもたく、どうしにあるきょうでんようじえんではえんしゃがとうか...  \n",
       "\n",
       "[501 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ed1afdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7027\n",
      "543\n",
      "501\n"
     ]
    }
   ],
   "source": [
    "print(len(train_split))\n",
    "print(len(test_split))\n",
    "print(len(val_split))\n",
    "#train_split['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afd62a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load kanji data\n",
    "kanji_df = pd.read_json(\"kanji.json\")\n",
    "kanji_df = kanji_df.drop(['strokes', 'grade', 'freq', 'jlpt_old', 'jlpt_new', 'meanings', 'wk_radicals', 'wk_readings_kun', 'wk_readings_on', 'wk_meanings', 'wk_level'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cdc3535",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>kana</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train-s1</td>\n",
       "      <td>ホッケーにはデンジャラスプレーの反則があるので、膝より上にボールを浮かすことは基本的に反則に...</td>\n",
       "      <td>[ホッケー, に, は, デンジャラス, プレー, の, 反則, が, ある, の, で, ...</td>\n",
       "      <td>ホッケーにはデンジャラスプレーのはんそくがあるので、しつよりじょうにボールをふかすことはきほ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train-s2</td>\n",
       "      <td>また行きたい、そんな気持ちにさせてくれるお店です。</td>\n",
       "      <td>[また, 行き, たい, 、, そんな, 気持ち, に, さ, せ, て, くれる, お, ...</td>\n",
       "      <td>またこうきたい、そんなきじちにさせてくれるおてんです。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train-s3</td>\n",
       "      <td>手に持った特殊な刃物を使ったアクロバティックな体術や、揚羽と薄羽同様にクナイや忍具を使って攻...</td>\n",
       "      <td>[手, に, 持っ, た, 特殊, な, 刃物, を, 使っ, た, アクロバティック, な...</td>\n",
       "      <td>しゅにじったとくしゅなじんぶつをしったアクロバティックなたいじゅつや、よううとはくうどうよう...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train-s4</td>\n",
       "      <td>3年次にはトータルオフェンスで2,892ヤードを獲得し、これは大学記録となった。</td>\n",
       "      <td>[3, 年次, に, は, トータル, オフェンス, で, 2, ,, 892, ヤード, ...</td>\n",
       "      <td>3ねんじにはトータルオフェンスで2,892ヤードをかくとくし、これはだいがくきろくとなった。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train-s5</td>\n",
       "      <td>葬儀の最中ですよ!</td>\n",
       "      <td>[葬儀, の, 最中, です, よ, !]</td>\n",
       "      <td>そうぎのさいちゅうですよ!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7022</th>\n",
       "      <td>train-s7160</td>\n",
       "      <td>「さくらちゃん」と呼ばれている。</td>\n",
       "      <td>[「, さくら, ちゃん, 」, と, 呼ば, れ, て, いる, 。]</td>\n",
       "      <td>「さくらちゃん」とこばれている。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7023</th>\n",
       "      <td>train-s7161</td>\n",
       "      <td>シェルマルケ氏は新憲法などをめぐり、アハメド暫定大統領と対立していた。</td>\n",
       "      <td>[シェルマルケ, 氏, は, 新, 憲法, など, を, めぐり, 、, アハメド, 暫定,...</td>\n",
       "      <td>シェルマルケしはしんけんほうなどをめぐり、アハメドざんていだいとうりょうとたいりつしていた。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7024</th>\n",
       "      <td>train-s7162</td>\n",
       "      <td>自らがオウム真理教ではない別のカルト団体に12年間所属していた経験をもとに,こう語りました。</td>\n",
       "      <td>[自ら, が, オウム, 真理, 教, で, は, ない, 別, の, カルト, 団体, に...</td>\n",
       "      <td>じらがオウムしんりきょうではないべつのカルトだんたいに12ねんかんしょぞくしていたけいけんを...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7025</th>\n",
       "      <td>train-s7163</td>\n",
       "      <td>紅い髪と同じ色の瞳という容姿に加え、眉と鎖骨の下の部分に二つずつ紅い球体が埋まっているという...</td>\n",
       "      <td>[紅い, 髪, と, 同じ, 色, の, 瞳, と, いう, 容姿, に, 加え, 、, 眉...</td>\n",
       "      <td>こういはつとどうじしょくのどうというようしにかえ、びとさこつのかのぶぶんににつずつこういきゅ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7026</th>\n",
       "      <td>train-s7164</td>\n",
       "      <td>“人生,棒に振らないように”するためにはカルト団体からの速やかな離脱が必要だと感じるのは記者...</td>\n",
       "      <td>[“, 人生, ,, 棒, に, 振ら, ない, よう, に, ”, する, ため, に, ...</td>\n",
       "      <td>“じんせい,ぼうにしんらないように”するためにはカルトだんたいからのそくやかなりだつがひつよ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7027 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              idx                                               text  \\\n",
       "0        train-s1  ホッケーにはデンジャラスプレーの反則があるので、膝より上にボールを浮かすことは基本的に反則に...   \n",
       "1        train-s2                          また行きたい、そんな気持ちにさせてくれるお店です。   \n",
       "2        train-s3  手に持った特殊な刃物を使ったアクロバティックな体術や、揚羽と薄羽同様にクナイや忍具を使って攻...   \n",
       "3        train-s4           3年次にはトータルオフェンスで2,892ヤードを獲得し、これは大学記録となった。   \n",
       "4        train-s5                                          葬儀の最中ですよ!   \n",
       "...           ...                                                ...   \n",
       "7022  train-s7160                                   「さくらちゃん」と呼ばれている。   \n",
       "7023  train-s7161                シェルマルケ氏は新憲法などをめぐり、アハメド暫定大統領と対立していた。   \n",
       "7024  train-s7162     自らがオウム真理教ではない別のカルト団体に12年間所属していた経験をもとに,こう語りました。   \n",
       "7025  train-s7163  紅い髪と同じ色の瞳という容姿に加え、眉と鎖骨の下の部分に二つずつ紅い球体が埋まっているという...   \n",
       "7026  train-s7164  “人生,棒に振らないように”するためにはカルト団体からの速やかな離脱が必要だと感じるのは記者...   \n",
       "\n",
       "                                                 tokens  \\\n",
       "0     [ホッケー, に, は, デンジャラス, プレー, の, 反則, が, ある, の, で, ...   \n",
       "1     [また, 行き, たい, 、, そんな, 気持ち, に, さ, せ, て, くれる, お, ...   \n",
       "2     [手, に, 持っ, た, 特殊, な, 刃物, を, 使っ, た, アクロバティック, な...   \n",
       "3     [3, 年次, に, は, トータル, オフェンス, で, 2, ,, 892, ヤード, ...   \n",
       "4                                 [葬儀, の, 最中, です, よ, !]   \n",
       "...                                                 ...   \n",
       "7022               [「, さくら, ちゃん, 」, と, 呼ば, れ, て, いる, 。]   \n",
       "7023  [シェルマルケ, 氏, は, 新, 憲法, など, を, めぐり, 、, アハメド, 暫定,...   \n",
       "7024  [自ら, が, オウム, 真理, 教, で, は, ない, 別, の, カルト, 団体, に...   \n",
       "7025  [紅い, 髪, と, 同じ, 色, の, 瞳, と, いう, 容姿, に, 加え, 、, 眉...   \n",
       "7026  [“, 人生, ,, 棒, に, 振ら, ない, よう, に, ”, する, ため, に, ...   \n",
       "\n",
       "                                                   kana  \n",
       "0     ホッケーにはデンジャラスプレーのはんそくがあるので、しつよりじょうにボールをふかすことはきほ...  \n",
       "1                           またこうきたい、そんなきじちにさせてくれるおてんです。  \n",
       "2     しゅにじったとくしゅなじんぶつをしったアクロバティックなたいじゅつや、よううとはくうどうよう...  \n",
       "3        3ねんじにはトータルオフェンスで2,892ヤードをかくとくし、これはだいがくきろくとなった。  \n",
       "4                                         そうぎのさいちゅうですよ!  \n",
       "...                                                 ...  \n",
       "7022                                   「さくらちゃん」とこばれている。  \n",
       "7023     シェルマルケしはしんけんほうなどをめぐり、アハメドざんていだいとうりょうとたいりつしていた。  \n",
       "7024  じらがオウムしんりきょうではないべつのカルトだんたいに12ねんかんしょぞくしていたけいけんを...  \n",
       "7025  こういはつとどうじしょくのどうというようしにかえ、びとさこつのかのぶぶんににつずつこういきゅ...  \n",
       "7026  “じんせい,ぼうにしんらないように”するためにはカルトだんたいからのそくやかなりだつがひつよ...  \n",
       "\n",
       "[7027 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As part of data collection, we need a dataset that is ONLY kana. \n",
    "# We could not find a dataset that had both kanji AND kana only version,\n",
    "# so we took a dataset and converted the kanji to kana. \n",
    "# kanji to kana is less ambiguous with how on vs kun readings work, but there is still some abiguity.\n",
    "# we recognize that here, in the dataset.\n",
    "def unkanjify(df):\n",
    "    new_sent = []\n",
    "    for word in df['tokens']:\n",
    "        #iterating list of chararacters\n",
    "        for char in word:\n",
    "            if char in kanji_df.columns:#is kanji\n",
    "                if char in kanji_df.columns or char in kanji_df.columns:\n",
    "                    if kanji_df[char].loc['readings_on']:\n",
    "                        new_sent.append(kanji_df[char].loc['readings_on'][0])\n",
    "                    else:\n",
    "                        new_sent.append(char)\n",
    "                #kun reading\n",
    "                else:\n",
    "                    for c in kanji_df[char].loc['readings_kun'][0]:\n",
    "                        if c == '.':\n",
    "                            continue\n",
    "                        new_sent.append(c)\n",
    "            else:#is not kanji\n",
    "                new_sent.append(char)\n",
    "    joined_sent = ''.join(new_sent)\n",
    "    return joined_sent\n",
    "\n",
    "# Applying the function to all splits (train, test and val)\n",
    "train_split_df['kana'] = train_split_df.apply(lambda x: unkanjify(x), axis=1) \n",
    "test_split_df['kana'] = test_split_df.apply(lambda x: unkanjify(x), axis=1) \n",
    "val_split_df['kana'] = val_split_df.apply(lambda x: unkanjify(x), axis=1) \n",
    "train_split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "58361eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertJapaneseTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nTFBertForMaskedLM requires the TensorFlow library but it was not found in your environment.\nHowever, we were able to find a PyTorch installation. PyTorch classes do not begin\nwith \"TF\", but are otherwise identically named to our TF classes.\nIf you want to use PyTorch, please use those classes instead!\n\nIf you really do want to use TensorFlow, please follow the instructions on the\ninstallation page https://www.tensorflow.org/install that match your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#tokenizer = AutoTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese\")\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#model = AutoModel.from_pretrained(\"cl-tohoku/bert-base-japanese\")\u001b[39;00m\n\u001b[0;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcl-tohoku/bert-base-japanese\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTFBertForMaskedLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcl-tohoku/bert-base-japanese\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\utils\\import_utils.py:992\u001b[0m, in \u001b[0;36mDummyObject.__getattr__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, key)\n\u001b[1;32m--> 992\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\utils\\import_utils.py:975\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# Raise the inverse error for PyTorch users trying to load TF classes\u001b[39;00m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m is_torch_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available():\n\u001b[1;32m--> 975\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(TF_IMPORT_ERROR_WITH_PYTORCH\u001b[38;5;241m.\u001b[39mformat(name))\n\u001b[0;32m    977\u001b[0m checks \u001b[38;5;241m=\u001b[39m (BACKENDS_MAPPING[backend] \u001b[38;5;28;01mfor\u001b[39;00m backend \u001b[38;5;129;01min\u001b[39;00m backends)\n\u001b[0;32m    978\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n",
      "\u001b[1;31mImportError\u001b[0m: \nTFBertForMaskedLM requires the TensorFlow library but it was not found in your environment.\nHowever, we were able to find a PyTorch installation. PyTorch classes do not begin\nwith \"TF\", but are otherwise identically named to our TF classes.\nIf you want to use PyTorch, please use those classes instead!\n\nIf you really do want to use TensorFlow, please follow the instructions on the\ninstallation page https://www.tensorflow.org/install that match your environment.\n"
     ]
    }
   ],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese\")\n",
    "#model = AutoModel.from_pretrained(\"cl-tohoku/bert-base-japanese\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('cl-tohoku/bert-base-japanese')\n",
    "model = TFBertForMaskedLM.from_pretrained('cl-tohoku/bert-base-japanese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e4ba0cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ba3de99",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputsKanji = tokenizer(train_split_df['text'].values.tolist(), max_length=100, truncation=True, padding='max_length', return_tensors='np')\n",
    "inputsKana = tokenizer(train_split_df['kana'].values.tolist(), max_length=100, truncation=True, padding='max_length', return_tensors='np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3c12e646",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputsKana['labels'] = inputsKanji['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ce2d735",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LEARNING_RATE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)    \n\u001b[1;32m----> 3\u001b[0m optimizer_bert \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(params \u001b[38;5;241m=\u001b[39m  model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[43mLEARNING_RATE\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LEARNING_RATE' is not defined"
     ]
    }
   ],
   "source": [
    "model.to(device)    \n",
    "\n",
    "optimizer_bert = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12a8fe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ids = []\n",
    "lbs = []\n",
    "idx = 0\n",
    "for inp in inputsKana.input_ids:\n",
    "    actual_tokens = list(set(range(100)) - \n",
    "                         set(np.where((inp == 101) | (inp == 102) \n",
    "                            | (inp == 0))[0].tolist()))\n",
    "    #We need to select 15% random tokens from the given list\n",
    "    num_of_token_to_mask = int(len(actual_tokens)*0.15)\n",
    "    token_to_mask = np.random.choice(np.array(actual_tokens), \n",
    "                                     size=num_of_token_to_mask, \n",
    "                                     replace=False).tolist()\n",
    "    #Now we have the indices where we need to mask the tokens\n",
    "    inp[token_to_mask] = 103\n",
    "    inp_ids.append(inp)\n",
    "    idx += 1\n",
    "#inp_ids = tf.convert_to_tensor(inp_ids)\n",
    "inputsKana['input_ids'] = inp_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7daa5a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BertModel' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m([inputsKana\u001b[38;5;241m.\u001b[39minput_ids,inputsKana\u001b[38;5;241m.\u001b[39mattention_mask],inputsKana\u001b[38;5;241m.\u001b[39mlabels,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1207\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1206\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1207\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1208\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BertModel' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "#model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "history = model.fit([inputsKana.input_ids,inputsKana.attention_mask],inputsKana.labels,verbose=1,batch_size=8,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bc6b5b",
   "metadata": {},
   "source": [
    "1. concatinate kana and kanji text and put a sperator token in between [SEP]\n",
    "some kana text [SEP] some kanji text\n",
    "\n",
    "2. randomly mask kanji text\n",
    "some kana text [SEP] some [MASK] text [MASK]\n",
    "***[MASK] is identified as 103\n",
    "\n",
    "3. train model\n",
    "\n",
    "4. predict a text as so\n",
    "\n",
    "another kana text [SEP] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa40ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
