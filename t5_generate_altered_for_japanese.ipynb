{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffd0823f",
   "metadata": {},
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "iws6VJu9gCwK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iws6VJu9gCwK",
    "outputId": "7befeac4-7f9c-460f-884a-22f92691598b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting utils\n",
      "  Downloading utils-1.0.1-py2.py3-none-any.whl (21 kB)\n",
      "Installing collected packages: utils\n",
      "Successfully installed utils-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers[sentencepiece] in c:\\users\\brand\\anaconda3\\lib\\site-packages (4.24.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\brand\\anaconda3\\lib\\site-packages (from transformers[sentencepiece]) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from transformers[sentencepiece]) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from transformers[sentencepiece]) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from transformers[sentencepiece]) (22.0)\n",
      "Requirement already satisfied: requests in c:\\users\\brand\\anaconda3\\lib\\site-packages (from transformers[sentencepiece]) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from transformers[sentencepiece]) (1.23.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from transformers[sentencepiece]) (2022.7.9)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from transformers[sentencepiece]) (0.13.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from transformers[sentencepiece]) (0.11.4)\n",
      "Collecting protobuf<=3.20.2\n",
      "  Downloading protobuf-3.20.2-cp310-cp310-win_amd64.whl (904 kB)\n",
      "     -------------------------------------- 904.0/904.0 kB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from transformers[sentencepiece]) (0.1.98)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers[sentencepiece]) (4.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\brand\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers[sentencepiece]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from requests->transformers[sentencepiece]) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from requests->transformers[sentencepiece]) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from requests->transformers[sentencepiece]) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from requests->transformers[sentencepiece]) (3.4)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.22.3\n",
      "    Uninstalling protobuf-4.22.3:\n",
      "      Successfully uninstalled protobuf-4.22.3\n",
      "Successfully installed protobuf-3.20.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
      "     -------------------------------------- 81.4/81.4 kB 912.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas in c:\\users\\brand\\anaconda3\\lib\\site-packages (from evaluate) (1.5.3)\n",
      "Requirement already satisfied: dill in c:\\users\\brand\\anaconda3\\lib\\site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\brand\\anaconda3\\lib\\site-packages (from evaluate) (22.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\brand\\anaconda3\\lib\\site-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from evaluate) (0.13.4)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\brand\\anaconda3\\lib\\site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from evaluate) (2.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from evaluate) (1.23.5)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from evaluate) (4.64.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from evaluate) (2022.11.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from evaluate) (2.28.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\brand\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\brand\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\brand\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
      "Installing collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: absl-py in c:\\users\\brand\\anaconda3\\lib\\site-packages (from rouge-score) (1.4.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\brand\\anaconda3\\lib\\site-packages (from rouge-score) (3.7)\n",
      "Requirement already satisfied: numpy in c:\\users\\brand\\anaconda3\\lib\\site-packages (from rouge-score) (1.23.5)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\brand\\anaconda3\\lib\\site-packages (from nltk->rouge-score) (1.1.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\brand\\anaconda3\\lib\\site-packages (from nltk->rouge-score) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from nltk->rouge-score) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\users\\brand\\anaconda3\\lib\\site-packages (from nltk->rouge-score) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\brand\\anaconda3\\lib\\site-packages (from click->nltk->rouge-score) (0.4.6)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py): started\n",
      "  Building wheel for rouge-score (setup.py): finished with status 'done'\n",
      "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24972 sha256=953affaeecb9a3b31a756960c4d5bf352bb4f0894d61abc9f4f1113213a1eff5\n",
      "  Stored in directory: c:\\users\\brand\\appdata\\local\\pip\\cache\\wheels\\3e\\94\\5c\\7ff8a51c53c1bbc8df4cac58aa4990ffbc6fa203e9f0808fdd\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: rouge-score\n",
      "Successfully installed rouge-score-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install utils\n",
    "%pip install transformers[sentencepiece]\n",
    "%pip install evaluate\n",
    "%pip install rouge-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3710beb7",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "636f41b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "636f41b1",
    "outputId": "7e6aa4f7-fa4c-4384-ed0d-38325d8c2350"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import *\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import evaluate\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "import torch\n",
    "from torch import cuda\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "# device = torch.device(\"cpu\")\n",
    "device\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bb3f59",
   "metadata": {},
   "source": [
    "### Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e3c94db",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "id": "7e3c94db",
    "outputId": "021f13fd-d344-45cb-9d7e-2456cf89f07f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d251c2529c02>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#model_checkpoint = \"cl-tohoku/bert-base-japanese\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sonoisa/t5-base-japanese-v2\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'AutoTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "#model_checkpoint = \"google/mt5-small\"#This can also be used, though it has different results\n",
    "model_checkpoint = \"sonoisa/t5-base-japanese-v1.1\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "86e3224e",
   "metadata": {
    "id": "86e3224e"
   },
   "outputs": [],
   "source": [
    "max_input_length = 128\n",
    "max_target_length = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac01a798",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "It is just an np.array of many different sentences. y is the target, x is the input. The index of each arrap relate to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "9862c66a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9862c66a",
    "outputId": "98386be1-0807-4751-d4e5-b74bd7d30fe7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((101,), (26,), (101,), (26,))"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([\"最近いろいろあって歌えなかったから、今日は歌いまくった！\",\n",
    "    \"どうして俺は彼らのように歌うことが出来ないんだ\",\n",
    "    \"人は食事を取らなければ死んでしまう\",\n",
    "    \"税金を払ったら実生活の始まりだ。\",\n",
    "    \"もう彼女には言えないよ。そんなに単純なことではなくなってきたからね。\",\n",
    "    \"お金を稼ぎたいならアメリカが一番だ\",\n",
    "    \"最新のバイオ技術によって、芋の臭みkを最小限に抑え、非常に飲みやすい「芋焼酎」です。\",\n",
    "    \"あなたは新しいことを勉強したいのだと思った。\",\n",
    "    \"野ねずみが農家の穀物を食べ尽くしていった。\",\n",
    "    \"とある映画を文庫化した—いや、映画の為に書かれたシナリオを小説として加筆修正し、日本語にローカライズしたものだ。\",\n",
    "    \"あの映画はえげつない\",\n",
    "    \"両親にこっぴどくしかられてしまいます。\",\n",
    "    \"ラザニアが大好きです\",\n",
    "    \"あれ？あなたまだここにいたのね！\",\n",
    "    \"心配しないで、楽しくいこう！\",\n",
    "    \"兵士たちの使命はその橋を破壊hすることだった\",\n",
    "     \"今、ようやくツケがまわってきたのだろう\",\n",
    "    \"料金は会計係へ払って下さい\",\n",
    "    \"僕のおごりですよ。\",\n",
    "    \"果樹栽培者がリンゴの接ぎ穂を台木に接ぎ木しました\",\n",
    "    \"アップルの新型ノートは予定通りに発表されるだろうか\",\n",
    "    \"冷蔵庫のドアを開いたらリンゴが落ちた\",\n",
    "    \"林檎は彼女によってナイフで半分に切られた\",\n",
    "    \"林檎の形は丸い\",\n",
    "    \"緑色である事がその種のりんごの特徴なのです\",\n",
    "    \"トップのリーダーは犬の行動学では「アルファと呼ばれ以下「ベータ「ガンマと続きます\",\n",
    "    \"こんな時は迎え酒に限ります\",\n",
    "    \"時々私の犬は夜中の間間に吠えます\",\n",
    "    \"次に私達に犬の世話をする時間があるか今一度一考えてみましょう\",\n",
    "    \"下校の途中で犬をつれた女の子と遊んだ\",\n",
    "    \"チューたろうは田中さんの犬です\",\n",
    "    \"古代のオーバーテクノロジーの武器は必ず制御ができなくなる\",\n",
    "    \"シャッターを押すだけで最新のテクノロジーがキレイな一枚に仕上げます\",\n",
    "    \"ただの本なら宇宙警察がでしゃばりはしないわ問題はこれがオーバーテクノロジーの塊だってこと\",\n",
    "    \"倫理の点から言うと技術関連の大原則は「現在への責任だが、「未来への責任」という新しい考え方が出てきた\",\n",
    "    \"この仕事の面白みは、常に技術が進化しているので、刺激を受け続けられることですね\",\n",
    "    \"発明や科学技術のために古い語が新しい意味をとるようになる場合が多い\",\n",
    "    \"古代のオーバーテクノロジーの武器は必ず制御ができなくなる\",\n",
    "    \"シャッターを押すだけで、最新のテクノロジーがキレイな一枚に仕上げます\",\n",
    "    \"ただの本なら、宇宙警察がでしゃばりはしないわ、問題はこれがオーバーテクノロジーの塊だってこと\",\n",
    "    \"彼は古代史の分野で突っ込んだ研究をしている\",\n",
    "    \"民主主義は古代ギリシャに始まった\",\n",
    "    \"父は古代史に関心を持っている\",\n",
    "    \"彼は船で何世紀も前に自分の土地を離れた古代の神様についての話を聞いていた\",\n",
    "    \"彼は古代神話に基づく小説を書いた\",\n",
    "    \"彼は古代史に精通している\",\n",
    "    \"何か重い兇器でやられたらしく、頭蓋骨は粉砕された\",\n",
    "    \"万が一に備えて、武器になるものを探した\",\n",
    "    \"秘密兵器の知識がある人は、我が身を危険な立場に置いている\",\n",
    "    \"彼は私に武器を向けた\",\n",
    "    \"彼は傘を武器として使った\",\n",
    "    \"原子爆弾は恐ろしい武器だ\",\n",
    "    \"世界的な全面核戦争が起これば、地球規模でこの「核の冬」が数カ月間も続くと言われています\",\n",
    "    \"問題は、いかに核戦争を避けるかである\",\n",
    "    \"放射能が原子力発電所から漏れた\",\n",
    "    \"文明は今や核戦争に脅かされている\",\n",
    "    \"彼らは声を大にして核実験反対を叫んだ\",\n",
    "    \"彼らは核兵器のことを気にかけているようだ\",\n",
    "    \"生物学は好きになれません\",\n",
    "    \"聞いたところでは、彼は生物を勉強するために渡米したそうだ\",\n",
    "    \"彼女は生物学の学位を持っている\",\n",
    "    \"彼は生物研究所に１０年近く従事している\",\n",
    "    \"彼は生物学の分野で研究している\",\n",
    "    \"彼は生物学に非常に関心をもっている\",\n",
    "    \"省エネのためにコンビニの２４時間営業を廃止しろ\",\n",
    "    \"暖房と同様に、冷房時の消費電力量を測定し、旧型と省エネ型（２００１年製）のエアコンを比較しました\",\n",
    "    \"ヘレンの言葉で私は急に力づいた\",\n",
    "    \"「ねこまっしぐら」というのは、飼い猫がエサに向かってまいしんする様子を表している\",\n",
    "    \"成歩堂先生の事務所が「エネルギー分野における世界有数の法律事務所」である\",\n",
    "    \"たまにはビール以外のお酒をちびちび舐めるのも良いでしょう\",\n",
    "    \"マックで軽く昼食をとって、スタバでコーヒーを飲んで、しゃぶしゃぶをしながら飲み会という流れだ\",\n",
    "    \"こちらの飲み物は単品となります\",\n",
    "    \"休みの前などは少し羽目を外して飲むのだが、杜仲茶割りで飲むと二日酔いが全くない\",\n",
    "    \"父は普通ビールを飲むが、今夜はワインを飲んだ\",\n",
    "    \"父は蒸留酒は飲まない\",\n",
    "    \"医者に相談して鎮静剤を処方してもらうのはどうでしょうか\",\n",
    "    \"診察室を出る間際、先生が「バイバイと手を振ってくださいました\",\n",
    "    \"近医で処方を希望したら露骨に嫌な顔をされた\",\n",
    "    \"うん前の先生に紹介してもらって、転院したの\",\n",
    "    \"「あ、は、はい・・・ごめん、玲姉」「コラ幾ら親戚とはいえ、私は先輩医師よ院内ではちゃんとケジメをつけなさい」\",\n",
    "    \"医者になれる日はまだほど遠い\",\n",
    "    \"何かしてみましょう\",\n",
    "    \"この世界の教育にはがっかりしてしまう\",\n",
    "    \"「信用して」と彼は言った\",\n",
    "    \"失礼だが、上記の記事にある３つの誤りを指摘しておきたい\",\n",
    "    \"あの方が言われる事を、何でもしてあげて下さい\",\n",
    "    \"彼は彼の人生の話を私にしてくれた\",\n",
    "    \"脅しによるリーダーシップは、いまぼくたちが目にするような結果を生み出しはしない\",\n",
    "    \"照明はツマミ一つで光量を変えられるようになっていて好きな明るさを演出出来るようになっている\",\n",
    "    \"文法的に正しい文章を作るよう心がけるべきだ\",\n",
    "    \"彼らは同じ製品をはるかにやすい原価で製造できる\",\n",
    "    \"農民は作物を作る\",\n",
    "    \"農家の人々は温室で作物を育てざるを得ないのです\",\n",
    "    \"そうしたなかで急速な進歩を遂げてきたのが、である\",\n",
    "    \"ママあのお姉ちゃんとお兄ちゃん、お手手繋いで、すっごく仲良しさんだね\",\n",
    "    \"普通、アマチュアでは250ヤード飛べばすごい飛距離だと言われます\",\n",
    "    \"皆さんは、モラルを大切にしていますか\",\n",
    "    \"いわゆる裏方仕事もたくさんあります\",\n",
    "    \"これは世界の常識であり、資源管理の大原則だ\",\n",
    "    \"そういう相手の前では、私の見せ掛けだけの怜悧な技術は、見抜かれた時に負けていたと思う\",\n",
    "    \"利口な生徒はそうした質問に簡単に答えられる\",\n",
    "    \"利口な学生達は早くテストを終えた\",\n",
    "    \"利口な学生であればそのような事はしないだろう\",\n",
    "    \"非常に賢くおとなしいので、この犬は私にとって良い友達です\",\n",
    "    \"彼女は利口というよりむしろ賢明である\",\n",
    "    \"赤道における経度1度当たりの長さ\",\n",
    "    \"昨日ゆっくり休んだ分、今日は頭が冴えている\",\n",
    "    \"その会社では高い専門性が要求される\",\n",
    "    \"容疑者は自白するまできびしい尋問を受けた\",\n",
    "    \"僕は彼に少なからず恩義がある\",\n",
    "    \"彼女は博士号を取得した\",\n",
    "    \"弊社は機械パーツの輸入を行っています\",\n",
    "    \"彼女は米国史を専攻するだろう\",\n",
    "    \"彼は大学で物理学を専攻することに決めた\",\n",
    "    \"前の会社では何でも屋に終始したので今度は専門職に就きたい\",\n",
    "    \"私は中世史を専攻している\",\n",
    "    \"今後、生物学を専攻する学生の数は増加するであろう\",\n",
    "    \"あなたは大学で何を専攻されましたか\",\n",
    "    \"アルミニウム、マグネシウム、シリコンなどの粉末が爆発する\",\n",
    "    \"怒鳴りつけたかったが思いとどまった\",\n",
    "    \"心臓が、どきどきして破裂しそう\",\n",
    "    \"蒸気ボイラーは爆発する可能性がある\",\n",
    "    \"そのニュースは彼の怒りを爆発させた\",\n",
    "    \"このゲームの目的は画面にあるすべての爆弾を爆発させることです\",\n",
    "    \"説明してもいいけど、君の脳みそ爆発するよ\",\n",
    "    \"勉強のしすぎで頭が爆発しそう\",\n",
    "    \"怒りが爆発する前に、ガス抜きしなきゃ\"])\n",
    "\n",
    "X = np.array([\"さいきんいろいろあってうたえなかtたから、きょうはうたいまくった！\",\n",
    "    \"どうしておれはかれらにのようにうたうことができないんだ。\",\n",
    "    \"ひとはしょくじをとらなければしんでしまう\",\n",
    "    \"ぜいきんをはらたらじっせいかつのはじまりだ。\",\n",
    "    \"もうかのじょにはいえないよ。そんなにたんじゅんなことではなくなてきたからね。\",\n",
    "    \"おかねをかせぎたいならアメリカがいちばんだ\",\n",
    "    \"さいしんのバイオぎじゅつによtて、いものくさみをさいしょうげんにおさえ、ひじょうにのみやすい「いもしょうちゅう」です。\",\n",
    "    \"あなたはあたらしいことをべんきょうしたいのだとおもった。\",\n",
    "    \"のねずみがのうかのこくもつをたべつくしていった。\",\n",
    "    \"とあるえいがをぶんこかした—いや、えいがのためにかかれたシナリオをしょうせつとしてかひつしゅうせいし、にほんごにロオカライズしたものだ。\",\n",
    "    \"あのえいがはえげつない\",\n",
    "    \"りょうしんにこっぴどくしかられてしまいます。\",\n",
    "    \"ラザニアがだいすきです\",\n",
    "    \"あれ？あなたまだここにいたのね！\",\n",
    "    \"しんぱいしないで、たのしくいこう！\",\n",
    "    \"へいしたちのしめいはそのはしをはかいすることだった\",\n",
    "    \"いま、ようやくツケがまわってきたのだろう\",\n",
    "    \"りょうきんはかいけいがかりへはらってください\",\n",
    "    \"ぼくのおごりですよ\",\n",
    "    \"かじゅさいばいしゃがリンゴのはぎほをだいぎにつぎきしました\",\n",
    "    \"アっプルのしんがたノオトはよていどおりにはっぴょうされるだろうか\",\n",
    "    \"れいぞうこのドアをひらいたらリンゴがおちた\",\n",
    "    \"りんごはかのじょによtてナイフではんぶんにきられた\",\n",
    "    \"りんごのかたちはまるい\",\n",
    "    \"りょくしょくであることがそのたねのりんごのとくちょうなのです\",\n",
    "    \"トっプのリイダアはいぬのこうどうがくではアルフアとよばれいかベエタガンマとつずきます\",\n",
    "    \"こんなときはむかえざけにかぎります\",\n",
    "    \"ときどきわたしのいぬはのにほえます\",\n",
    "    \"にわたしたちにいぬのせわをするじかんがあるかいまどかんがえてみましょう\",\n",
    "    \"げこうのとちゅうでいぬをつれたおんなのことあそんだ\",\n",
    "    \"チュウたろはたなかさんのいぬです\",\n",
    "    \"こだいのオオバアテクノロジイのぶきはかならずせいぎょができなくなる\",\n",
    "    \"シャっタアをおすだけでさいしんのテクノロジイがキレイなにしあげます\",\n",
    "    \"ただのほんならうちゅうけいさつがでしゃばりはしないわもんだいはこれがオオバアテクノロジイのかたまりだってこと\",\n",
    "    \"りんりのてんからいうとぎじゅつかんれんのだいげんそくはげんざいへのせきにんだがみらいへのせきにんというあたらしいかんがえかたがでてきた\",\n",
    "    \"このしごとのおもしろみはつねにぎじゅつがしんかしているのでしげきをうけつずけられることですね\",\n",
    "    \"はつめいやかがくぎじゅつのためにふるいかたりがあたらしいいみをとるようになるばあいがおおい\",\n",
    "    \"こだいのオオバアテクノロジイのぶきはかならずせいぎょができなくなる\",\n",
    "    \"シャっタアをおすだけでさいしんのテクノロジイがキレイなにしあげます\",\n",
    "    \"ただのほんならうちゅうけいさつがでしゃばりはしないわもんだいはこれがオオバアテクノロジイのかたまりだってこと\",\n",
    "    \"かれはこだいしのぶん'やでつっこんだけんきゅうをしている\",\n",
    "    \"みんしゅしゅぎはこだいギリシャにはじまった\",\n",
    "    \"ちちはこだいしにかんしんをもっている\",\n",
    "    \"かれはふねでなにせいきもまえにじぶんのとちをはなれたこだいのかみさまについてのはなしをきいていた\",\n",
    "    \"かれはこだいしんわにもとずくしょうせつをかいた\",\n",
    "    \"かれはこだいしにせいつうしている\",\n",
    "    \"なにかおもいきょうきでやられたらしくずがいこつはふんさいされた\",\n",
    "    \"まんがいちにそなえてぶきになるものをさがした\",\n",
    "    \"ひみつへいきのちしきがあるひとはわがみをきけんなたちばにおいている\",\n",
    "    \"かれはわたしにぶきをむけた\",\n",
    "    \"かれはかさをぶきとしてつかった\",\n",
    "    \"げんしばくだんはおそろしいぶきだ\",\n",
    "    \"せかいてきなぜんめんかくせんそうがおこればちきゅうきぼでこのかくのふゆがすうかげつかんもつずくといわれています\",\n",
    "    \"もんだいはいかにかくせんそうをさけるかである\",\n",
    "    \"ほうしゃのうがげんしりょくはつでんしょからもれた\",\n",
    "    \"ぶんめいはいまやかくせんそうにおびやかされている\",\n",
    "    \"かれらはこえをだいにしてかくじっけんはんたいをさけんだ\",\n",
    "    \"かれらはかくへいきのことをきにかけているようだ\",\n",
    "    \"せいぶつがくはすきになれません\",\n",
    "    \"きいたところではかれはせいぶつをべんきょうするためにとべいしたそうだ\",\n",
    "    \"かのじょはせいぶつがくのがくいをもっている\",\n",
    "    \"かれはせいぶつけんきゅうじょに１０ねんちかくじゅうじしている\",\n",
    "    \"かれはせいぶつがくのぶんやでけんきゅうしている\",\n",
    "    \"かれはせいぶつがくにひじょうにかんしんをもっている\",\n",
    "    \"しょうえねのためにコンビニの２４えいぎょうをはいししろ\",\n",
    "    \"だんぼうとどうようにれいぼうじのしょうひでんりょくりょうをそくていしきゅうがたしょうえね（２００１ねんせい）のエアコンをひかくしました\",\n",
    "    \"ヘレンのことばでわたしはきゅうにちからずいた\",\n",
    "    \"ねこまっしぐらというのはかいねこがエサにむかってまいしんするようすをあらわしている\",\n",
    "    \"なるふどうせんせいのじむしょがエネルギイぶんやにおけるせかいゆうすうのほうりつじむしょである\",\n",
    "    \"たまにはビイルいがいのおさけをちびちびなめるのもよいでしょう\",\n",
    "    \"マックでかるくちゅうしょくをとってスタバでコオヒイをのんでしゃぶしゃぶをしながらのみかいというながれだ\",\n",
    "    \"こちらののみものはたんぴんとなります\",\n",
    "    \"やすみのまえなどはすこしはめをはずしてのむのだがもりなかちゃわりでのむとふつかよいがまったくない\",\n",
    "    \"ちちはふつうビイルをのむがこん'やはワインをのんだ\",\n",
    "    \"ちちはじょうりゅうしゅはのまない\",\n",
    "    \"いしゃにそうだんしてちんせいざいをしょほうしてもらうのはどうでしょうか\",\n",
    "    \"しんさつしつをでるまぎわせんせいがバイバイとてをふってくださいました\",\n",
    "    \"きんいでしょほうをきぼうしたらろこつにいやなかおをされた\",\n",
    "    \"うんまえのせんせいにしょうかいしてもらっててんいんしたの\",\n",
    "    \"あははい・・・ごめんれいあねコラいくらしんせきとはいえわたしはせんぱいいしよいんないではちゃんとケジメをつけなさい\",\n",
    "    \"いしゃになれるひはまだほどとおい\",\n",
    "    \"なにかしてみましょう\",\n",
    "    \"このせかいのきょういくにはがっかりしてしまう\",\n",
    "    \"しんようしてとかれはいった\",\n",
    "    \"しつれいだがじょうきのきじにある３みっつのあやまりをしてきしておきたい\",\n",
    "    \"あのほうがいわれることをなにでもしてあげてください\",\n",
    "    \"かれはかれのじんせいのはなしをわたしにしてくれた\",\n",
    "    \"おどしによるリイダアシっプはいまぼくたちがめにするようなけっかをうみだしはしない\",\n",
    "    \"しょうめいはツマミひとつでひかりりょうをかえられるようになっていてすきなあかるさをえんしゅつできるようになっている\",\n",
    "    \"ぶんぽうてきにただしいぶんしょうをつくるようこころがけるべきだ\",\n",
    "    \"かれらはおなじせいひんをはるかにやすいげんかでせいぞうできる\",\n",
    "    \"のうみんはさくもつをつくる\",\n",
    "    \"のうかのひとびとはおんしつでさくもつをそだてざるをえないのです\",\n",
    "    \"そうしたなかできゅうそくなしんぽをとげてきたのがイっである\",\n",
    "    \"ママあのおねえちゃんとおにいちゃのてしゅつないですっごくなかよしさんだね\",\n",
    "    \"ふつうアマチュアでは250ヤアドとべばすごいひきょりだといわれます\",\n",
    "    \"みなさんはモラルをたいせつにしていますか\",\n",
    "    \"いわゆるうらかたしごともたくさなります\",\n",
    "    \"これはせかいのじょうしきでありしげんかんりのだいげんそくだ\",\n",
    "    \"そういうあいてのまえではわたしのみせかけだけのれいりなぎじゅつはみぬかれたときにまけていたとおもう\",\n",
    "    \"りこうなせいとはそうしたしつもんにかんたんにこたえられる\",\n",
    "    \"りこうながくせいたちははやくテストをおえた\",\n",
    "    \"りこうながくせいであればそのようなことはしないだろう\",\n",
    "    \"ひじょうにかしこくおとなしいのでこのいぬはわたしにとってよいともだちです\",\n",
    "    \"かのじょはりこうというよりむしろけんめいである\",\n",
    "    \"せきどうにおけるけいど1あたりのながさ\",\n",
    "    \"きのうゆっくりやすんだぶんきょうはあたまがさえている\",\n",
    "    \"そのかいしゃではたかいせんもんせいがようきゅうされる\",\n",
    "    \"ようぎしゃはじはくするまできびしいじんもんをうけた\",\n",
    "    \"ぼくはかれにすくなからずおんぎがある\",\n",
    "    \"かのじょははかせごうをしゅとくした\",\n",
    "    \"へいしゃはきかいパアツのゆにゅうをおこなっています\",\n",
    "    \"かのじょはべいこくしをせんこうするだろう\",\n",
    "    \"かれはだいがくでぶつりがくをせんこうすることにきめた\",\n",
    "    \"まえのかいしゃではなにでもやにしゅうししたのでこんどはせんもんしょくにつきたい\",\n",
    "    \"わたしはちゅうせいしをせんこうしている\",\n",
    "    \"こんごせいぶつがくをせんこうするがくせいのかずはぞうかするであろう\",\n",
    "    \"あなたはだいがくでなにをせんこうされましたか\",\n",
    "    \"アルミニウムマグネシウムシリコンなどのふんまつがばくはつする\",\n",
    "    \"どなりつけたかったがおもいとどまった\",\n",
    "    \"しんぞうがどきどきしてはれつしそう\",\n",
    "    \"じょうきボイラアはばくはつするかのうせいがある\",\n",
    "    \"そのニュウスはかれのいかりをばくはつさせた\",\n",
    "    \"このゲエムのもくてきはがめんにあるすべてのばくだんをばくはつさせることです\",\n",
    "    \"せつめいしてもいいけどきみののうみそばくはつするよ\",\n",
    "    \"べんきょうのしすぎであたまがばくはつしそう\",\n",
    "    \"いかりがばくはつするまえにガスぬきしなきゃ\"])\n",
    "\n",
    "#X = np.array(X)\n",
    "##y = np.array(y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "f9d78dcc",
   "metadata": {
    "id": "f9d78dcc"
   },
   "outputs": [],
   "source": [
    "class MultiLabelDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, text, labels, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text = text\n",
    "        self.labels = labels\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.text[index]\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "#         token_type_ids = inputs[\"token_type_ids\"]\n",
    "        \n",
    "        text = self.labels[index][0]\n",
    "        labels = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        \n",
    "#         print(inputs)\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(mask, dtype=torch.long),\n",
    "#             'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'labels': torch.tensor(labels['input_ids'], dtype=torch.long)\n",
    "#                 'token_type_ids': torch.tensor(labels['token_type_ids'], dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7ba33a",
   "metadata": {},
   "source": [
    "#### Tokenize the Dataset & Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "d5861de2",
   "metadata": {
    "id": "d5861de2"
   },
   "outputs": [],
   "source": [
    "tokenized_datasets = {}\n",
    "tokenized_datasets['train'] = MultiLabelDataset(X_train, y_train, tokenizer, max_input_length)\n",
    "tokenized_datasets['validation'] = MultiLabelDataset(X_test, y_test, tokenizer, max_input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "f5de1e9e",
   "metadata": {
    "id": "f5de1e9e"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_train_epochs = 3\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(tokenized_datasets[\"train\"]) // batch_size\n",
    "model_name = model_checkpoint.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "1b13c803",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1b13c803",
    "outputId": "57d717b6-7f86-4a74-b631-9c74f3ae04a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"/data/{model_name}-japanese\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5.6e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    predict_with_generate=True,\n",
    "    logging_steps=logging_steps,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "5c6e1e5b",
   "metadata": {
    "id": "5c6e1e5b"
   },
   "outputs": [],
   "source": [
    "\n",
    "rouge_score = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    # Decode generated summaries into text\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=False)\n",
    "    # Replace -100 in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    # Decode reference summaries into text\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=False)\n",
    "    # ROUGE expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    # Compute ROUGE scores\n",
    "    result = rouge_score.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    # Extract the median scores\n",
    "    result = {key: value * 100 for key, value in result.items()}\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "cd154b6d",
   "metadata": {
    "id": "cd154b6d"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "5bea184b",
   "metadata": {
    "id": "5bea184b"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9347d831",
   "metadata": {},
   "source": [
    "### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "17717f2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "17717f2f",
    "outputId": "e94b1f8f-c97d-419e-f160-a9e419af0e7b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 03:35, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>14.571500</td>\n",
       "      <td>11.359753</td>\n",
       "      <td>11.152800</td>\n",
       "      <td>3.238900</td>\n",
       "      <td>10.641900</td>\n",
       "      <td>10.579300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>14.523800</td>\n",
       "      <td>11.079609</td>\n",
       "      <td>9.564100</td>\n",
       "      <td>1.619400</td>\n",
       "      <td>9.400800</td>\n",
       "      <td>9.345400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>14.469900</td>\n",
       "      <td>10.980495</td>\n",
       "      <td>15.072700</td>\n",
       "      <td>7.180600</td>\n",
       "      <td>14.402900</td>\n",
       "      <td>14.379000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=12, training_loss=14.090277353922525, metrics={'train_runtime': 237.4203, 'train_samples_per_second': 1.276, 'train_steps_per_second': 0.051, 'total_flos': 14928245250048.0, 'train_loss': 14.090277353922525, 'epoch': 3.0})"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b81a9cb",
   "metadata": {},
   "source": [
    "Save Model if wanted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "7a4848dc",
   "metadata": {
    "id": "7a4848dc"
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"./kana_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "fg4jI6UOqjlu",
   "metadata": {
    "id": "fg4jI6UOqjlu"
   },
   "outputs": [],
   "source": [
    "kana_model = AutoModelForSeq2SeqLM.from_pretrained(\"./kana_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b6d356",
   "metadata": {},
   "source": [
    "# Test Model. Put a Japanese sentence in the text and pass it through the tokenizer and run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "cNNos3zWqucm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cNNos3zWqucm",
    "outputId": "d3ef00f0-a402-42bf-b1f4-4aadb38d1621"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  261,  5120,   266, 27422,   782,   269,   273,   394,  3450,  3107,\n",
      "           272,  4701,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "tensor([[    0, 32099,   287,   261, 32075,   260,   261,  5120,   266, 27422,\n",
      "           782,   269,   273,   394,  3450,  3107,   272,  4701,   260, 15011]])\n",
      "<pad><extra_id_0>し <extra_id_24>。 ひとはしょくじをとらなければしんでしまう。こころ\n"
     ]
    }
   ],
   "source": [
    "text = \"ひとはしょくじをとらなければしんでしまう\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")   \n",
    "print(inputs)\n",
    "#outputs = kana_model.generate(inputinput_ids)\n",
    "outputs = trainer.model.generate(input_ids=inputs[\"input_ids\"],attention_mask=inputs[\"attention_mask\"],do_sample=False,)\n",
    "print(outputs)\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "8UpRSzuUrffK",
   "metadata": {
    "id": "8UpRSzuUrffK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
